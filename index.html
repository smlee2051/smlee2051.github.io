<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sunmi's Research</title>
  <style>
    body {
      font-family: sans-serif;
      max-width: 800px;
      margin: 40px auto;
      padding: 20px;
      line-height: 1.6;
    }
    h1, h2 {
      color: #333;
    }
    a {
      color: #0066cc;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>

  <h1>ì„ ë¯¸ (Sunmi) | Ph.D. Student in AI & Statistics</h1>
  <p>Hi! I'm a Ph.D. student focusing on <strong>time series forecasting</strong>, <strong>LLMs</strong>, and <strong>statistical learning theory</strong>.</p>

  <h2>ğŸ”— Links</h2>
  <ul>
    <li><a href="https://github.com/your-username">GitHub</a></li>
    <li><a href="https://scholar.google.com">Google Scholar</a></li>
    <li><a href="mailto:your@email.com">Email</a></li>
  </ul>

  <h2>ğŸ“„ Recent Projects</h2>
  <ul>
    <li><strong>LLMTime</strong>: Time-series prediction using pre-trained LLMs. [<a href="https://github.com/your-username/LLMTime">Code</a>]</li>
    <li><strong>Autoformer Extension</strong>: Enhanced version of Autoformer for multivariate forecasting. [<a href="https://github.com/your-username/autoformer-enhanced">Code</a>]</li>
  </ul>

  <h2>ğŸ“ Publications</h2>
  <ul>
    <li>"Time-Series Forecasting with Transformer-based LLMs", under review at NeurIPS 2025.</li>
    <li>"Uncertainty-aware Temporal Embedding for Forecasting", ICML 2024.</li>
  </ul>

</body>
</html>
